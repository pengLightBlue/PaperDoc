# 大模型术语

**1.** **[大模型](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=大模型&zhida_source=entity)**：一般指1亿以上参数的模型，但是这个标准一直在升级，目前万亿参数以上的模型也有了。[大语言模型](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=大语言模型&zhida_source=entity)（Large Language Model，LLM）是针对语言的大模型。

**2.** **175B、60B、540B等**：这些一般指参数的个数，B是Billion/十亿的意思，175B是1750亿参数，这是ChatGPT大约的参数规模。目前OpenAI的模型参数已经超过万亿（Trillion），DeepSeek发布的R1模型达到671B。

**3.** **强化学习**：（Reinforcement Learning）一种机器学习的方法，通过从外部获得激励来校正学习方向从而获得一种自适应的学习能力。

**4.** **基于人工反馈的强化学习（[RLHF](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=RLHF&zhida_source=entity)）**：（Reinforcement Learning from Human Feedback）构建人类反馈数据集，训练一个激励模型，模仿人类偏好对结果打分，这是GPT-3后时代大语言模型越来越像人类对话核心技术。

**5.** **[涌现](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=涌现&zhida_source=entity)**：（Emergence）或称创发、突现、呈展、演生，是一种现象。许多小实体相互作用后产生了大实体，而这个大实体展现了组成它的小实体所不具有的特性。研究发现，模型规模达到一定阈值以上后，会在多步算术、大学考试、单词释义等场景的准确性显著提升，称为涌现。

**6.** **[泛化](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=泛化&zhida_source=entity)**：（Generalization）模型泛化是指一些模型可以应用（泛化）到其他场景，通常为采用迁移学习、[微调](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=微调&zhida_source=entity)等手段实现泛化。

**7.** **微调**：（FineTuning）针对大量数据训练出来的预训练模型，后期采用业务相关数据进一步训练原先模型的相关部分，得到准确度更高的模型，或者更好的泛化。

**8.** **指令微调**：（Instruction FineTuning），针对已经存在的预训练模型，给出额外的指令或者标注数据集来提升模型的性能。

**9.** **[思维链](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=思维链&zhida_source=entity)**：（Chain-of-Thought，CoT）。通过让大语言模型（LLM）将一个问题拆解为多个步骤，一步一步分析，逐步得出正确答案。需指出，针对复杂问题，LLM直接给出错误答案的概率比较高。思维链可以看成是一种指令微调。

**10、[Token](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=Token&zhida_source=entity)**：Token是大模型各种算法的基本输入单元，可以认为是一个单词或者一个短语。那么到底是单次还是短语呢？实际上是全包含的关系。Token是语言中有独立含义的最小实体，一个单词，一个短语都是Token。

*例如，DeepSeek帮助手册的描述是：**一个英文字符~0.3个Token；一个中文字符~0.6个Token**。到底一个大模型中有多少不同的Token，这个可以数一数tokenizer.json，DeepSeek V3是12万个左右。需要注意，Token在大模型计算中，是一个数字，数字和具体的实体是一一对应的。*

**11、[注意力](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=注意力&zhida_source=entity)**。（Attention）注意力是Google Transformer论文提出的概念。我开始也有些困惑，后来才豁然开朗，这个概念只有Google提出来最合：对Token的注意力，和对搜索引擎Keyword的重要性是一样的。随着数据规模的增长，重要性强的Token就会脱颖而出。

**12、[温度](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=温度&zhida_source=entity)**：（Temperature）温度用来调节大模型生成内容的策略，从而决定生成内容的风格。较高的温度会让概率分布更平滑，增加随机性，而较低的温度会让分布更尖锐，选择概率最高的结果。例如，温度趋近于0时，模型会选择最可能的token，导致确定性输出；温度高时，输出更多样化，但可能包含更多错误或不相关的内容。

*例如，DeepSeek中，T=0.3~0.7（严谨模式）、T=0.8~1.2（平衡模式）、T=1.5~2.0（创意模式）*

**13、RLHF和[GRPO](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=GRPO&zhida_source=entity)**：（Group Relative Policy Optimization）如前所述，RL1983年Barto和Sutton提出，也是2025年的图灵奖获得者。强化学习是机器学习的一种方法论，用于智能体通过感知外界环境来决策学习方向，例如机械臂的运动控制等。大模型发展后，RL获得大量应用，目前看有RLHF和GRPO两类方式，通过激励模型可以

*例如，GPT采用人工标注模型生成数据，训练奖励模型，并重新训练，用奖励模型对训练参数打分来优化大模型，上述方法被称为RLHF（Reinforcement Learning with Human Feedback）。DeepSeek R1首先采用高质量数据来微调V3，但是采用GPRO（Group Relative Policy Optimization）对参数打分，临近结束用拒绝采样方法获得微调数据，结合V3的人工问答等数据，再次微调V3，最后获得R1。*

**14、[混合专家MoE](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=混合专家MoE&zhida_source=entity)**：（Mixture of Expert）Experts指的是多个独立训练的神经网络子模块或组件。每个Expert各自专注于数据的不同方面或者不同的任务部分。通过动态选择不同子模块来处理输入数据的不同部分，MoE能够有效地增加模型容量而不显著增加推理成本。可以认为MoE之前的模型是一个密集模型（Dense），MoE则生成一组相对稀疏的专家组。DeepSeek的创新是，采用大量的Expert来优化推理占用的显存，毕竟每次仅加载少量Experts就可以完成推理。

**15、[蒸馏](https://zhida.zhihu.com/search?content_id=224814908&content_type=Article&match_order=1&q=蒸馏&zhida_source=entity)**：（Distillation）这是一种用优质大模型的生成数据来微调其他模型的技术。

*这不算什么新技术，只是被DeepSeek发现并委以重任了。DeepSeek用R1生成的80万数据对Qwen和Llama的开源模型做了蒸馏，大幅度提升了模型推理性能。*

**16、数据标注**：（Data Annotation）数据标注是机器学习的前提和基础预先准备好配套的数据和数据说明、解释和分析信息，非常类似准备教材和教案的工作。标注的目标是为模型提供清晰、结构化的输入，帮助其学习特定任务或改进生成质量。根据任务不同，数据标注有很多种方法。我有一页片子，贴在这里：

![img](https://pic1.zhimg.com/v2-8d375042b08063b1864dad018e52d270_1440w.jpg)

**17、预训练**：（Pre-Training）是指在目标任务的数据集上进行正式训练之前，先在一个大规模的、通用的数据集上对模型进行初步训练的过程。这种方法可以帮助模型学习到广泛的知识和特征表示，从而在后续的任务中更好地泛化和迁移这些知识。这里面后续任务就包括了微调、蒸馏，当然也可以是对行业模型的再训练。

